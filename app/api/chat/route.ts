import { streamText } from 'ai';
import { createOpenAI } from '@ai-sdk/openai';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { NextRequest, NextResponse } from 'next/server';
import { MessageRequestBody } from '@/types/chat';

// åˆå§‹åŒ–é»˜è®¤çš„ AI æä¾›å•†å®ä¾‹
// é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä»¬ä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– API å¯†é’¥
// (OPENAI_API_KEY, GOOGLE_API_KEY)
const defaultOpenAI = createOpenAI();
const defaultGoogle = createGoogleGenerativeAI(
    {
        apiKey: process.env.GOOGLE_API_KEY,
    }
);

// Groq ä¹Ÿä½¿ç”¨ä¸ OpenAI å…¼å®¹çš„ APIï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºå…¶åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„å®ä¾‹
const groq = createOpenAI({
    baseURL: 'https://api.x.ai/v1',
    apiKey: process.env.GROK_API_KEY,
});

export const dynamic = 'force-dynamic';

export async function POST(req: NextRequest) {
    try {
        const { messages, model, apiKey } = (await req.json()) as MessageRequestBody & { apiKey?: string };

        let provider;
        let chatModel;

        // æ ¹æ®æ¨¡å‹åç§°é€‰æ‹©æä¾›å•†å’Œæ¨¡å‹
        switch (true) {
            case model.startsWith('gpt-'):
                // å¦‚æœç”¨æˆ·æä¾›äº†è‡ªå®šä¹‰ API Keyï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„å®ä¾‹
                provider = apiKey ? createOpenAI({ apiKey }) : defaultOpenAI;
                chatModel = provider(model);
                break;

            case model.startsWith('grok-'): // Groq çš„æ¨¡å‹é€šå¸¸ä¸ä»¥ 'grok-' å¼€å¤´ï¼Œä½†æˆ‘ä»¬éµå¾ªç°æœ‰é€»è¾‘
                // Grok éœ€è¦è‡ªå·±çš„ API Key
                provider = apiKey ? createOpenAI({ baseURL: 'https://api.groq.com/openai/v1', apiKey }) : groq;
                // æ³¨æ„ï¼šæ‚¨éœ€è¦ä¼ é€’ Grok æ”¯æŒçš„å®é™…æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ 'llama3-8b-8192'
                // è¿™é‡Œæˆ‘ä»¬å‡è®¾å‰ç«¯ä¼ é€’çš„ 'grok-...' åªæ˜¯ä¸€ä¸ªæ ‡è¯†ç¬¦ï¼Œå®é™…æ¨¡å‹åæ˜¯å›ºå®šçš„æˆ–å¦å¤–ä¼ é€’
                chatModel = provider(model); // ç¤ºä¾‹æ¨¡å‹ï¼Œè¯·æ›¿æ¢ä¸ºå®é™…æ¨¡å‹
                break;

            case model.startsWith('gemini-'):
                provider = apiKey ? createGoogleGenerativeAI({ apiKey }) : defaultGoogle;
                chatModel = provider(model, {
                    safetySettings: [
                        {
                            category: 'HARM_CATEGORY_HARASSMENT',
                            threshold: 'BLOCK_NONE',
                        },
                        {
                            category: 'HARM_CATEGORY_HATE_SPEECH',
                            threshold: 'BLOCK_NONE',
                        },
                        {
                            category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
                            threshold: 'BLOCK_NONE',
                        },
                        {
                            category: 'HARM_CATEGORY_DANGEROUS_CONTENT',
                            threshold: 'BLOCK_NONE',
                        },
                    ],
                });
                break;

            default:
                return NextResponse.json({ error: `Model ${model} not supported.` }, { status: 400 });
        }

        const mappedMessages = messages.map(message => ({
            role: message.role as 'user' | 'assistant',
            content: message.content,
        }));

        console.log("Messages sent to model:", JSON.stringify(mappedMessages, null, 2));

        // ä½¿ç”¨ç»Ÿä¸€çš„ streamText API è°ƒç”¨æ¨¡å‹
        const result = await streamText({
            model: chatModel,
            // ğŸ‘‡ **è¿™é‡Œæ˜¯å…³é”®ä¿®æ”¹**
            // å°†æ‚¨çš„ messages æ•°ç»„æ˜ å°„ä¸º AI SDK å¯æ¥å—çš„æ ¼å¼
            // æˆ‘ä»¬æ˜ç¡®å‘Šè¯‰ TypeScriptï¼Œrole åªä¼šæ˜¯ 'user' æˆ– 'assistant'
            messages: mappedMessages,
            temperature: 0.7,
        });

        // å°†ç»“æœç›´æ¥è½¬æ¢ä¸ºæµå¼å“åº”
        return result.toDataStreamResponse();

    } catch (error) {
        console.error("[Chat API] Error:", error);
        const errorMessage = error instanceof Error ? error.message : "An unknown error occurred";
        return NextResponse.json({ error: "Internal Server Error", details: errorMessage }, { status: 500 });
    }
}